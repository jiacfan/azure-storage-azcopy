// Copyright Â© 2017 Microsoft <wastore@microsoft.com>
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

package ste

import (
	"github.com/Azure/azure-pipeline-go/pipeline"
	"github.com/Azure/azure-storage-azcopy/common"
)

/////////////////////////////////////////////////////////////////////////////////////////////////
// ISenderBase is the abstraction contains common sender behaviors.
/////////////////////////////////////////////////////////////////////////////////////////////////
type ISenderBase interface {
	// ChunkSize returns the chunk size that should be used
	ChunkSize() uint32

	// NumChunks returns the number of chunks that will be required for the target file
	NumChunks() uint32

	// RemoteFileExists is called to see whether the file already exists at the remote location (so we know whether we'll be overwriting it)
	RemoteFileExists() (bool, error)

	// Prologue is called automatically before the first chunkFunc is generated.
	// Implementation should do any initialization that is necessary - e.g.
	// creating the remote file for those destinations that require an explicit
	// creation step.
	Prologue(state PrologueState)

	// Epilogue will be called automatically once we know all the chunk funcs have been processed.
	// Implementation should interact with its jptm to do
	// post-success processing if transfer has been successful so far,
	// or post-failure processing otherwise.
	Epilogue()
}

// PrologueState contains info necessary for different sending operations' prologue.
type PrologueState struct {
	// Leading bytes are the early bytes of the file, to be used
	// for mime-type detection (or nil if file is empty or the bytes code
	// not be read).
	leadingBytes []byte
}

func (ps PrologueState) CanInferContentType() bool {
	return len(ps.leadingBytes) > 0 // we can have a go, if we have some leading bytes
}

func (ps PrologueState) GetInferredContentType(jptm IJobPartTransferMgr) string {
	headers, _ := jptm.BlobDstData(ps.leadingBytes)
	return headers.ContentType
	// TODO: this BlobDstData method is messy, both because of the blob/file distinction and
	//     because its so coarse grained.  Do something about that one day.
}

/////////////////////////////////////////////////////////////////////////////////////////////////
// Abstraction of the methods needed to copy one file from URL to a remote location
/////////////////////////////////////////////////////////////////////////////////////////////////
type s2sCopier interface {
	ISenderBase

	// GenerateCopyFunc returns a func() that will copy the specified portion of the source URL file to the remote location.
	GenerateCopyFunc(chunkID common.ChunkID, blockIndex int32, adjustedChunkSize int64, chunkIsWholeFile bool) chunkFunc
}

type s2sCopierFactory func(jptm IJobPartTransferMgr, srcInfoProvider s2sSourceInfoProvider, destination string, p pipeline.Pipeline, pacer *pacer) (s2sCopier, error)

/////////////////////////////////////////////////////////////////////////////////////////////////
// Abstraction of the methods needed to upload one file to a remote location
/////////////////////////////////////////////////////////////////////////////////////////////////
type uploader interface {
	ISenderBase

	// GenerateUploadFunc returns a func() that will upload the specified portion of the local file to the remote location
	// Instead of taking local file as a parameter, it takes a helper that will read from the file. That keeps details of
	// file IO out of the upload func, and lets that func concentrate only on the details of the remote endpoint
	GenerateUploadFunc(chunkID common.ChunkID, blockIndex int32, reader common.SingleChunkReader, chunkIsWholeFile bool) chunkFunc
}

type uploaderFactory func(jptm IJobPartTransferMgr, destination string, p pipeline.Pipeline, pacer *pacer, sip sourceInfoProvider) (uploader, error)

/////////////////////////////////////////////////////////////////////////////////////////////////

func getNumChunks(fileSize int64, chunkSize uint32) uint32 {
	numChunks := uint32(1) // we always map zero-size source files to ONE (empty) chunk
	if fileSize > 0 {
		chunkSizeI := int64(chunkSize)
		numChunks = common.Iffuint32(
			fileSize%chunkSizeI == 0,
			uint32(fileSize/chunkSizeI),
			uint32(fileSize/chunkSizeI)+1)
	}
	return numChunks
}

func createSendToRemoteChunkFunc(jptm IJobPartTransferMgr, id common.ChunkID, body func()) chunkFunc {
	// For senders(uploader and s2sCopier), we set the chunk status to done as soon as the chunkFunc completes.
	// But we don't do that for downloads, since for those the chunk is not "done" until its flushed out
	// by the ChunkedFileWriter. (The ChunkedFileWriter will set the status to done at that time.)
	return createChunkFunc(true, jptm, id, body)
}

// createChunkFunc adds a standard prefix, which all chunkFuncs require, to the given body
func createChunkFunc(setDoneStatusOnExit bool, jptm IJobPartTransferMgr, id common.ChunkID, body func()) chunkFunc {
	return func(workerId int) {

		// BEGIN standard prefix that all chunk funcs need
		defer jptm.ReportChunkDone() // whether successful or failed, it's always "done" and we must always tell the jptm

		jptm.OccupyAConnection() // TODO: added the two operations for debugging purpose. remove later
		defer jptm.ReleaseAConnection()

		if jptm.WasCanceled() {
			jptm.LogChunkStatus(id, common.EWaitReason.Cancelled())
			return
		} else {
			if setDoneStatusOnExit {
				defer jptm.LogChunkStatus(id, common.EWaitReason.ChunkDone())
			}
		}
		// END standard prefix

		body()
	}
}
